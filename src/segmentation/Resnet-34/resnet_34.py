# -*- coding: utf-8 -*-
"""ResNET-34.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mgJx4n4JjtP6HwUNQo0UzV3YnYDAA8qw
"""

# -*- coding: utf-8 -*-
# U-Net with ResNet-34 encoder (PyTorch)
# Includes:
# 1) ImageNet normalization
# 2) Encoder freeze + BN eval (small batch size)
# 3) BCE + Dice loss for small object segmentation
# 4) Metrics: IoU, Dice, Precision, Recall, Pixel Accuracy

import os
import json
import numpy as np
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from sklearn.model_selection import train_test_split
from google.colab import drive

# --- Mount drive if using Colab ---
drive.mount('/content/drive')

# --- Paths & hyperparameters ---
BASE_PATH = '/content/drive/My Drive/Aligned_Sheets/'
JSON_PATH = os.path.join(BASE_PATH, 'dataset_updated.json')
MASKS_PATH = os.path.join(BASE_PATH, 'segmentation_masks')
MODEL_PATH = os.path.join(BASE_PATH, 'bubble_segmentation_resnet34.pth')

BATCH_SIZE = 2
TARGET_SIZE = (416, 576)
EPOCHS = 30
LEARNING_RATE = 1e-4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Device:", DEVICE)

# -------------------------
# Dataset
# -------------------------
class BubbleDataset(Dataset):
    def __init__(self, image_paths, mask_paths, target_size=(416,576), augment=False):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.target_size = target_size
        self.augment = augment
        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
        self.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        mask_path = self.mask_paths[idx]

        img = cv2.imread(img_path)
        if img is None:
            img = np.zeros((self.target_size[0], self.target_size[1], 3), dtype=np.uint8)
        else:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (self.target_size[1], self.target_size[0]))  # (w,h)

        mask = np.load(mask_path)
        mask = cv2.resize(mask, (self.target_size[1], self.target_size[0]), interpolation=cv2.INTER_NEAREST)
        if mask.ndim == 2:
            mask = np.expand_dims(mask, axis=-1)

        # Normalize image to ImageNet
        img = img.astype(np.float32) / 255.0
        img = (img - self.mean[None, None, :]) / self.std[None, None, :]
        img = np.transpose(img, (2,0,1))  # CHW
        mask = np.transpose(mask.astype(np.float32), (2,0,1))  # 1,H,W

        return torch.tensor(img, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)

# -------------------------
# Model: ResNet34 encoder + UNet decoder
# -------------------------
def conv_block(in_ch, out_ch, groups=8):
    g = groups if out_ch % groups == 0 else 1
    return nn.Sequential(
        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),
        nn.GroupNorm(g, out_ch),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),
        nn.GroupNorm(g, out_ch),
        nn.ReLU(inplace=True)
    )

class ResNet34_UNet(nn.Module):
    def __init__(self, pretrained=True):
        super().__init__()
        resnet = models.resnet34(pretrained=pretrained)

        # Encoder
        self.initial = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)  # H/2
        self.maxpool = resnet.maxpool  # H/4
        self.encoder1 = resnet.layer1  # 64, H/4
        self.encoder2 = resnet.layer2  # 128, H/8
        self.encoder3 = resnet.layer3  # 256, H/16
        self.encoder4 = resnet.layer4  # 512, H/32

        # Decoder
        self.up4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.dec4 = conv_block(512+256, 256)

        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.dec3 = conv_block(256+128, 128)

        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.dec2 = conv_block(128+64, 64)

        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.dec1 = conv_block(64+64, 32)

        self.up0 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.final_conv = nn.Sequential(
            nn.Conv2d(32,16,kernel_size=3,padding=1,bias=False),
            nn.GroupNorm(4,16),
            nn.ReLU(inplace=True),
            nn.Conv2d(16,1,kernel_size=1)
        )

    def forward(self, x):
        x0 = self.initial(x)
        x1 = self.maxpool(x0)
        e1 = self.encoder1(x1)
        e2 = self.encoder2(e1)
        e3 = self.encoder3(e2)
        e4 = self.encoder4(e3)

        d4 = self.up4(e4)
        d4 = torch.cat([d4,e3],dim=1)
        d4 = self.dec4(d4)

        d3 = self.up3(d4)
        d3 = torch.cat([d3,e2],dim=1)
        d3 = self.dec3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2,e1],dim=1)
        d2 = self.dec2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1,x0],dim=1)
        d1 = self.dec1(d1)

        out = self.up0(d1)
        out = self.final_conv(out)
        return out

# -------------------------
# Freeze encoder + BN eval
# -------------------------
def freeze_encoder_and_bn(model):
    for name, param in model.named_parameters():
        if name.startswith('initial') or name.startswith('maxpool') or name.startswith('encoder'):
            param.requires_grad = False

    def _bn_eval(m):
        if isinstance(m, nn.BatchNorm2d):
            m.eval()
            for p in m.parameters():
                p.requires_grad = False
    model.apply(_bn_eval)

# -------------------------
# Loss: BCE + Dice
# -------------------------
class DiceLoss(nn.Module):
    def __init__(self, smooth=1e-6):
        super().__init__()
        self.smooth = smooth
    def forward(self, logits, targets):
        probs = torch.sigmoid(logits)
        targets = targets.float()
        num = 2*(probs*targets).view(probs.size(0),-1).sum(dim=1) + self.smooth
        den = probs.view(probs.size(0),-1).sum(dim=1) + targets.view(targets.size(0),-1).sum(dim=1) + self.smooth
        dice = num/den
        return 1.0 - dice.mean()

# -------------------------
# Metrics
# -------------------------
EPS = 1e-6
def sigmoid(x): return torch.sigmoid(x)

def iou_batch(y_true,y_pred,threshold=0.5):
    y_pred = (sigmoid(y_pred) > threshold).float()
    intersection = (y_true*y_pred).view(y_true.size(0),-1).sum(dim=1)
    union = y_true.view(y_true.size(0),-1).sum(dim=1) + y_pred.view(y_pred.size(0),-1).sum(dim=1) - intersection
    iou = torch.where(union>0, intersection/union, torch.ones_like(intersection))
    return iou.mean().item()

def dice_batch(y_true,y_pred,threshold=0.5,smooth=EPS):
    y_pred = (sigmoid(y_pred) > threshold).float()
    intersection = (y_true*y_pred).view(y_true.size(0),-1).sum(dim=1)
    union = y_true.view(y_true.size(0),-1).sum(dim=1) + y_pred.view(y_pred.size(0),-1).sum(dim=1)
    dice = (2.*intersection + smooth)/(union + smooth)
    return dice.mean().item()

def precision_batch(y_true,y_pred,threshold=0.5,smooth=EPS):
    y_pred = (sigmoid(y_pred) > threshold).float()
    tp = (y_true*y_pred).view(y_true.size(0),-1).sum(dim=1)
    pp = y_pred.view(y_pred.size(0),-1).sum(dim=1)
    return ((tp + smooth)/(pp + smooth)).mean().item()

def recall_batch(y_true,y_pred,threshold=0.5,smooth=EPS):
    y_pred = (sigmoid(y_pred) > threshold).float()
    tp = (y_true*y_pred).view(y_true.size(0),-1).sum(dim=1)
    pos = y_true.view(y_true.size(0),-1).sum(dim=1)
    return ((tp+smooth)/(pos+smooth)).mean().item()

def pixel_accuracy_batch(y_true,y_pred,threshold=0.5):
    y_pred = (sigmoid(y_pred) > threshold).float()
    correct = (y_true==y_pred).float()
    return correct.mean().item()

# -------------------------
# Bounding boxes from mask
# -------------------------
def get_bbox_from_mask(mask, threshold=0.5):
    binary_mask = (mask>threshold).astype(np.uint8)
    contours,_ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    bboxes = []
    for cnt in contours:
        if cv2.contourArea(cnt)>100:
            x,y,w,h = cv2.boundingRect(cnt)
            bboxes.append([x,y,x+w,y+h])
    return bboxes

# -------------------------
# Load dataset
# -------------------------
with open(JSON_PATH,'r') as f:
    data = json.load(f)

image_paths, mask_paths = [], []
for item in data:
    try:
        img_path = os.path.join(BASE_PATH,item['path'])
        if not os.path.exists(img_path): continue
        folder_num = int(item['path'].split('/')[0])
        mask_filename = os.path.splitext(os.path.basename(item['path']))[0]+"_mask.npy"
        mask_path = os.path.join(MASKS_PATH,f"folder_{folder_num:03d}",mask_filename)
        if os.path.exists(mask_path):
            image_paths.append(img_path)
            mask_paths.append(mask_path)
    except: continue

train_imgs, val_imgs, train_masks, val_masks = train_test_split(
    image_paths, mask_paths, test_size=0.2, random_state=42
)

train_ds = BubbleDataset(train_imgs, train_masks, target_size=TARGET_SIZE)
val_ds   = BubbleDataset(val_imgs, val_masks, target_size=TARGET_SIZE)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

# -------------------------
# Model, loss, optimizer
# -------------------------
model = ResNet34_UNet(pretrained=True).to(DEVICE)
freeze_encoder_and_bn(model)
criterion_bce = nn.BCEWithLogitsLoss()
criterion_dice = DiceLoss()
lambda_dice = 1.0
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='max',
    factor=0.1,
    patience=5
)


# -------------------------
# Training loop
# -------------------------
best_val_iou = -np.inf
earlystop_patience = 10
earlystop_counter = 0
history = {'loss':[],'val_loss':[],'iou_metric':[],'val_iou_metric':[],
           'dice_coefficient':[],'val_dice_coefficient':[],
           'precision_metric':[],'val_precision_metric':[],
           'recall_metric':[],'val_recall_metric':[],
           'pixel_accuracy':[],'val_pixel_accuracy':[]}

for epoch in range(1,EPOCHS+1):
    model.train()
    running_loss=0.0; n_batches=0
    train_iou=0.0; train_dice=0.0; train_prec=0.0; train_rec=0.0; train_pixacc=0.0
    loop = tqdm(train_loader,desc=f"Epoch {epoch}/{EPOCHS} - train",leave=False)
    for imgs,masks in loop:
        imgs = imgs.to(DEVICE); masks = masks.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion_bce(outputs,masks) + lambda_dice*criterion_dice(outputs,masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item(); n_batches+=1
        train_iou += iou_batch(masks,outputs)
        train_dice += dice_batch(masks,outputs)
        train_prec += precision_batch(masks,outputs)
        train_rec += recall_batch(masks,outputs)
        train_pixacc += pixel_accuracy_batch(masks,outputs)

    avg_train_loss = running_loss/max(1,n_batches)
    avg_train_iou  = train_iou/max(1,n_batches)
    avg_train_dice = train_dice/max(1,n_batches)
    avg_train_prec = train_prec/max(1,n_batches)
    avg_train_rec  = train_rec/max(1,n_batches)
    avg_train_pixacc = train_pixacc/max(1,n_batches)

    # Validation
    model.eval()
    val_loss=0.0; n_val=0
    val_iou=0.0; val_dice=0.0; val_prec=0.0; val_rec=0.0; val_pixacc=0.0
    with torch.no_grad():
        loop = tqdm(val_loader,desc=f"Epoch {epoch}/{EPOCHS} - val",leave=False)
        for imgs,masks in loop:
            imgs = imgs.to(DEVICE); masks = masks.to(DEVICE)
            outputs = model(imgs)
            loss = criterion_bce(outputs,masks) + lambda_dice*criterion_dice(outputs,masks)
            val_loss += loss.item(); n_val+=1
            val_iou += iou_batch(masks,outputs)
            val_dice += dice_batch(masks,outputs)
            val_prec += precision_batch(masks,outputs)
            val_rec += recall_batch(masks,outputs)
            val_pixacc += pixel_accuracy_batch(masks,outputs)

    avg_val_loss = val_loss/max(1,n_val)
    avg_val_iou  = val_iou/max(1,n_val)
    avg_val_dice = val_dice/max(1,n_val)
    avg_val_prec = val_prec/max(1,n_val)
    avg_val_rec  = val_rec/max(1,n_val)
    avg_val_pixacc = val_pixacc/max(1,n_val)

    scheduler.step(avg_val_iou)

    if avg_val_iou>best_val_iou:
        best_val_iou = avg_val_iou
        torch.save({'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'epoch': epoch,
                    'val_iou': best_val_iou}, MODEL_PATH)
        earlystop_counter = 0
        print(f"Saved best model at epoch {epoch} (val_iou={best_val_iou:.4f})")
    else:
        earlystop_counter +=1
        print(f"No improvement for {earlystop_counter} epochs (best {best_val_iou:.4f})")
    if earlystop_counter>=earlystop_patience:
        print("Early stopping triggered.")
        break

    # Save history
    history['loss'].append(avg_train_loss)
    history['val_loss'].append(avg_val_loss)
    history['iou_metric'].append(avg_train_iou)
    history['val_iou_metric'].append(avg_val_iou)
    history['dice_coefficient'].append(avg_train_dice)
    history['val_dice_coefficient'].append(avg_val_dice)
    history['precision_metric'].append(avg_train_prec)
    history['val_precision_metric'].append(avg_val_prec)
    history['recall_metric'].append(avg_train_rec)
    history['val_recall_metric'].append(avg_val_rec)
    history['pixel_accuracy'].append(avg_train_pixacc)
    history['val_pixel_accuracy'].append(avg_val_pixacc)

    print(f"Epoch {epoch}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}, val_iou={avg_val_iou:.4f}")

# -------------------------
# Plot curves
# -------------------------
plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(history['loss'],label='Train Loss')
plt.plot(history['val_loss'],label='Val Loss')
plt.legend(); plt.title('Loss Evolution')

plt.subplot(1,2,2)
plt.plot(history['iou_metric'],label='Train IoU')
plt.plot(history['val_iou_metric'],label='Val IoU')
plt.legend(); plt.title('IoU Evolution')
plt.tight_layout()
plt.show()

plt.figure()
plt.plot(history['dice_coefficient'],label='Train Dice')
plt.plot(history['val_dice_coefficient'],label='Val Dice')
plt.legend(); plt.title('Dice Evolution')
plt.show()

# -------------------------
# Visualization
# -------------------------
def visualize_prediction(idx=0, model=model, threshold=0.5):
    model.eval()
    img_path = val_imgs[idx]
    mask_path = val_masks[idx]
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    true_mask = np.load(mask_path)

    h,w = img_rgb.shape[:2]
    img_resized = cv2.resize(img_rgb,(TARGET_SIZE[1],TARGET_SIZE[0]))/255.0
    img_resized = (img_resized - np.array([0.485,0.456,0.406])) / np.array([0.229,0.224,0.225])
    input_tensor = torch.tensor(np.transpose(img_resized,(2,0,1))[None,...],dtype=torch.float32).to(DEVICE)

    with torch.no_grad():
        pred_logits = model(input_tensor)[0,0].cpu().numpy()
        pred_mask = sigmoid(torch.tensor(pred_logits)).numpy()

    boxes = [(int(x*w/TARGET_SIZE[1]), int(y*h/TARGET_SIZE[0]),
              int(x2*w/TARGET_SIZE[1]), int(y2*h/TARGET_SIZE[0]))
             for x,y,x2,y2 in get_bbox_from_mask(pred_mask,threshold=threshold)]

    plt.figure(figsize=(15,5))
    plt.subplot(1,3,1); plt.imshow(img_rgb); plt.title('Original Image'); plt.axis('off')
    plt.subplot(1,3,2); plt.imshow(pred_mask,cmap='gray'); plt.title('Predicted Mask'); plt.axis('off')
    img_boxes = img_rgb.copy()
    for x1,y1,x2,y2 in boxes:
        cv2.rectangle(img_boxes,(x1,y1),(x2,y2),(0,255,0),2)
    plt.subplot(1,3,3); plt.imshow(img_boxes); plt.title('Detected Bubbles'); plt.axis('off')
    plt.tight_layout()
    plt.show()

    print(f"Detected {len(boxes)} bubbles:")
    for i,b in enumerate(boxes):
        print(f"Bubble {i+1}: {b}")

for i in range(min(5,len(val_imgs))):
    visualize_prediction(i)

# -------------------------
# Final evaluation on validation set
# -------------------------
model.eval()
val_iou = 0.0
val_dice = 0.0
val_prec = 0.0
val_rec = 0.0
val_pixacc = 0.0
n_val = 0

with torch.no_grad():
    for imgs, masks in tqdm(val_loader, desc="Final evaluation"):
        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)
        outputs = model(imgs)

        val_iou += iou_batch(masks, outputs)
        val_dice += dice_batch(masks, outputs)
        val_prec += precision_batch(masks, outputs)
        val_rec += recall_batch(masks, outputs)
        val_pixacc += pixel_accuracy_batch(masks, outputs)
        n_val += 1

avg_val_iou = val_iou / n_val
avg_val_dice = val_dice / n_val
avg_val_prec = val_prec / n_val
avg_val_rec = val_rec / n_val
avg_val_pixacc = val_pixacc / n_val

print("\n--- Final Validation Metrics ---")
print(f"IoU: {avg_val_iou:.4f}")
print(f"Dice: {avg_val_dice:.4f}")
print(f"Precision: {avg_val_prec:.4f}")
print(f"Recall: {avg_val_rec:.4f}")
print(f"Pixel Accuracy: {avg_val_pixacc:.4f}")